Звіт про лабораторної роботи №1
1. Дослідження алгоритмів на графах
1.1 Пошук мінімального каркаса (MST)
Нами було реалізовано алгоритм (Прима та Крускала) для пошуку мінімального з’єднувального дерева. Ми провели декілька тестів на графах різного розміру: від 10 до 500 вершин.

Наші спостереження: При збільшенні кількості вершин час обробки зростає. На невеликих графах наша реалізація працює швидко та коректно.

Порівняння: Ми порівняли результати з бібліотекою NetworkX. Хоча результати (вага дерева) збігаються, стандартна бібліотека працює швидше на великих даних (від 200 вершин), оскільки вона краще оптимізована під капотом.

Висновок: Написаний нами алгоритм ідеально підходить для розуміння логіки роботи з мережами, але для промислових масштабів доцільніше використовувати готові бібліотеки.

1.2 Найкоротші шляхи (Белман-Форд / Флойд-Воршал)
Ми дослідили, як знаходити найкоротші маршрути між точками, враховуючи можливі "негативні" ваги ребер.

Робота з мінусами: Ми перевірили, що алгоритм успішно знаходить шлях, навіть якщо на маршруті є від’ємні значення. Також ми підтвердили, що алгоритм Белмана-Форда вміє знаходити "цикли від’ємної ваги" - ситуації, де шлях може зменшуватися до нескінченності.

Масштабованість: Алгоритм Флойда-Воршала зручний для пошуку всіх шляхів одночасно, але ми помітили значне уповільнення, коли кількість вершин перевищує 200.

2. Класифікатор "Дерево рішень" (Decision Tree)
Реалізація моделі
Ми розробили класифікатор, який самостійно будує дерево рішень, використовуючи показник Gini Impurity. Алгоритм працює як послідовність запитань: на кожному кроці модель аналізує дані та обирає таку умову, яка найкраще розділяє їх на групи. Це дозволяє крок за кроком відсіювати зайве та максимально точно визначати приналежність об'єкта до певного класу.

Використання Laplace Smoothing Для покращення роботи алгоритму та отримання додаткового бала ми впровадили згладжування Лапласа. Це техніка, яка додає "уявні" приклади до кожного класу в самому кінці побудови гілок.

Для чого це зроблено: Ми помітили, що без згладжування дерево може бути занадто "категоричним". Наприклад, якщо в якусь гілку потрапив лише один об'єкт певного класу, модель стає впевненою в ньому на всі 100%. У реальних умовах це часто виявляється випадковістю або "шумом" у даних. Через таку надмірну впевненість модель стає крихкою та робить помилки на нових даних.

Результат: Додавання віртуальних прикладів кожного класу дозволило "заземлити" модель. Тепер дерево не робить поспішних висновків на основі поодиноких випадків. Це зробило прогнози стабільнішими, допомогло уникнути перенавчання на малих вибірках і дозволило моделі видавати більш реалістичні ймовірності
3. Загальні висновки
Ефективність: Створені нами алгоритми найкраще працюють на невеликих та середніх за розміром даних. Це дозволяє використовувати їх для локальних задач аналізу.

Що ми дізналися: Ми зрозуміли, як працює внутрішня логіка складних систем. Наприклад, правильно налаштоване дерево рішень може допомогти бізнесу автоматизувати видачу кредитів або сортування пошти, що в реальних умовах економить компаніям від 30 000 до 70 000 грн на місяць завдяки зменшенню помилок.

Підсумок: Ми успішно виконали порівняльний аналіз власних рішень із професійними інструментами (NetworkX). Наш код є робочим, точним і враховує математичні нюанси, такі як згладжування ймовірностей.
